{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Level1_20211027_Optimizer_CNN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python [conda env:psd] *","language":"python","name":"conda-env-psd-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Wl_NSyTOWA3W"},"source":["# 20211008 (Optimizer, CNN)\n","\n","5기 Level 1 Optimizer, CNN 자료입니다."]},{"cell_type":"markdown","metadata":{"id":"SadlGdRnWA3Z"},"source":["# Contents"]},{"cell_type":"markdown","metadata":{"id":"S0hdG8QiWA3b"},"source":["* Optimizer\n","1. Grdient Descent Optimizer의 등장 배경\n","2. Momentum 계열 Optimizer\n","3. Adaptive Grdient 계열 Optimizer\n","4. Adaptive Moment Estimator 계열 Optimizer\n","\n","* CNN\n","5. Pooling Layer와 Convolution Layer"]},{"cell_type":"markdown","metadata":{"id":"DHuzRu-oGuAV"},"source":["해당 교육자료는 다음 자료를 참고하여 작성되었습니다.\n","\n","[1] An overview of gradient descent optimization algorithms (https://arxiv.org/pdf/1609.04747.pdf) <br>\n","[2] http://taewan.kim/post/cnn/"]},{"cell_type":"markdown","metadata":{"id":"kRO8vs2c7QTn"},"source":["# 1. Gradient Descent Optimizer Algorithms"]},{"cell_type":"markdown","metadata":{"id":"FC_dvVaB7QTo"},"source":["우리가 Machine Learning을 통해서 하고자 하는 것은 결국 Loss를 최소화할 수 있는 Loss Function의 parameters $\\theta ^*$를 찾는 것입니다. 이러한 $\\theta ^*$를 찾는 방법으로는 여러 가지가 있겠지만, Deep Learning에서는 경사하강법(Gradient Descent)을 주로 사용합니다. 경사하강법은 Object function $J(\\theta)$의 gradient $\\nabla_{\\theta} J(\\theta)$와 반대되는 방향으로 parameter들을 update하면서 $J(\\theta)$를 최소화하는 기법을 의미합니다. 또한, 여기에서 이러한 parameter를 변경하는 정도(step size)를 \"learning rate\"라고 이야기하며, 보통 $\\eta$로 표기합니다.\n","\n","Optimizer는 Gradient Descent를 보다 효율적으로 사용하여, 보다 빠르게, 그리고 정확하게 Loss가 Global Minimum에 도달할 수 있도록 도와주는 장치입니다. 더 이상 Loss Function이 convex하다는 보장이 없기 때문에, 기존의 Gradient Descent 알고리즘 역시 정상적으로 작동된다는 것을 보장할 수 없습니다. 이러한 부분들을 Optimizer가 해결해줄 것이며, 이에 관하여 알아보기 전에, 우선 이의 뼈대가 되는 (Batch) Gradient Descent부터 확인해보고, 이를 개선할 수 있는 방법에는 어떠한 것들이 있는지 알아봅시다."]},{"cell_type":"code","metadata":{"id":"8d0ga-xcHtD9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vsXNAHtw7QTq"},"source":["## 1-1. Batch Gradient Descent (BGD)"]},{"cell_type":"markdown","metadata":{"id":"89R88QMR7QTr"},"source":["$$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta)$$\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function\n","일반적으로 우리가 아는 gradient descent\n","에타는 learning rate,losff fuction의 gradient"]},{"cell_type":"markdown","metadata":{"id":"IPRFzLwh7QTr"},"source":["Vanilla Gradient Descent Algorithm으로, 그냥 Gradient Descent(GD)라고도 합니다. 우리가 가지고 있는 모든 train data를 한 번에 학습시키고, 한 번에 parameter를 update하는 방식으로, 해당 방식에는 다섯 가지 문제점이 존재합니다.\n","\n","1. 속도가 느리다.\n","2. parameter들이 update 되는 과정을 중간에 확인할 수 없다.\n","3. Memory가 허용하는 범위를 벗어나게 되면 사용이 불가능한 algorithm이다.\n","4. Local Minima, 혹은 Saddle Point에 갇힐 가능성을 배제하지 못한다.\n","5. 모든 parameter에 대해서 동일한 step size를 주고 있다."]},{"cell_type":"markdown","metadata":{"id":"U4GY4twn7QTs"},"source":["## 1-2. Stochastic Gradient Descent (SGD)"]},{"cell_type":"markdown","metadata":{"id":"EfXpdDDw7QTt"},"source":["$$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta; X^{(i)}; y^{(i)})$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function"]},{"cell_type":"markdown","metadata":{"id":"v6Qq9xtx7QTt"},"source":["원래의 의미: <br>\n","임의로 전체 data 중 한 개를 뽑은 후, 이에 대한 gradient를 계산하고 step을 진행하는 구조입니다. 위에서 언급된 GD의 다섯 가지 문제점들 중 1 ~ 3번을 해결하였으나(1000개가 있다면 하나씩 뽑는걸 1000번 뽑는다.), 한 번 parameter를 update할 때 random하게 한 건의 data를 뽑아서 training에 사용하다(반복되어서 나올수도 있다. 사용되는 data와 없는 data 존재할 수 있다.) 보니 정확도가 GD에 비해서 다소 떨어지게 된다는 단점을 가지고 있습니다. 이는 모든 data가 같은 확률로 뽑히기 때문에 (data의 분포가 Uniform Distrubution을 따르기 때문에) 어떠한 data는 여러 번 사용될 수도 있고, 어떠한 데이터는 training에 사용되지 않을 수도 있기 때문입니다."]},{"cell_type":"markdown","metadata":{"id":"L9PThld17QTt"},"source":["$$\\theta \\leftarrow \\theta - \\eta \\nabla_\\theta J(\\theta; X^{(i: i + n)}; y^{(i: i + n)})$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function"]},{"cell_type":"markdown","metadata":{"id":"CvU6YKag7QTu"},"source":["현재의 의미: <br>\n","i+n개 가져오는거 가령 200~300개정도. 기존의 SGD의 문제점(특정 data가 중복적으로 사용되거나, 특정 data가 training에 사용되지 않는 일이 생길 수 있다는 점)을 해결하고자 dataset을 여러 개의 Mini-Batch로 나눈 후, 하나의 Mini-Batch마다 gradient를 계산하여 parameter를 update하는 구조입니다. 기존의 SGD보다는 계산 속도가 다소 느려지겠지만, 여전히 Vanilla GD보다는 빠르며, SGD의 문제점도 해결하여 Vanilla GD와 거의 근접한 수준의 성능을 보여줍니다. 또한, Mini-Batch마다의 data 구성은 random(이는 shuffle 통해서 구현한다)하기 때문에, \"stochastic\"이라는 특성은 남아있다고 볼 수 있습니다. 현재 많은 Deep Learning Framework들은 이러한 점을 적극 반영하여 Mini-Batch를 모두 합치면 하나의 dataset이 되는 구조로 Mini-Batch를 구성하고 있습니다. 우리가 \"Batch Size\"로 지정하는 크기는 엄밀하게 말해서는 이 Mini-Batch의 크기입니다.\n","\n","1000개를 100씩 나눔 이 100개 다 돌려서 총데이터수만큼 학습됬을 때 그것 에포크, 배치는 한번에 얼마나 들어가는가(여기서는 100개)"]},{"cell_type":"markdown","metadata":{"id":"K5Rv5z5M7QTu"},"source":["현재는 후자의 개념이 SGD로 자리잡고 있으나, 엄밀하게 구분해야 하는 상황이라면, 전자를 SGD, 후자를 Mini-Batch GD로 구분하는 편입니다."]},{"cell_type":"markdown","metadata":{"id":"z1Smxrtx7QTv"},"source":["## 1-3. \"SGD가 GD보다 빠르다\"는 것의 의미"]},{"cell_type":"markdown","metadata":{"id":"dEjQFGXI7QTw"},"source":["우리가 n개의 data를 학습시키려 한다고 가정해봅시다. GD를 이용하면 n개의 data를 통한 parameter update가 1회 이루어질 것이고, SGD(원래의 의미)를 이용하면 1개의 data를 통한 parameter update가 n회 이루어질 것입니다. 그렇다면, 이론상으로는 update가 n회 진행되는 SGD가 더 느려야 할 것입니. (GD는 n개의 data에 대한 계산 후 1회만 update하는 반면, SGD는 계산도 n번, update도 n번 이루어지기 때문입니다.) 하지만 이는 어디까지나 \"연산 속도\"에 관한 이야기입니다. 사실, 우리는 GD가 data n개에 관한 연산을 모두 마친 후 parameter를 update한다는 점을 생각해보아야 할 필요가 있습니다. 연산을 마치기 이전에 이미 global minimum에 수렴했을 수도 있기 때문입니다. 이 점이 SGD의 \"수렴 속도\"가 일반적으로 GD보다 빠른 이유이며, 우리가 \"SGD가 GD보다 빠르다\"고 이야기하는 것은 이 수렴 속도에 관한 비교입니다. (혹자는 위의 연산 속도 비교는 어디까지나 이론적인 계산에 기반한 것이므로, 현실에서는 컴퓨팅 능력의 한계로 인하여 n번 계산하고 n번 update하는 SGD가 더 빨리 연산을 마친다고 이야기하기도 합니다.)\n","\n","간혹 1회의 parameter update에 소요되는 시간을 기준으로 \"SGD가 GD보다 빠르다\"고 이야기하기도 하나, 단 1회의 parameter update가 진행된 SGD는 GD에 비해 정확도가 다소 부족하기 때문에, 이는 적절한 비교가 아닙니다."]},{"cell_type":"markdown","metadata":{"id":"DDon1zDD7QTw"},"source":["# 2. Momentum 계열"]},{"cell_type":"markdown","metadata":{"id":"KUwTXoCh7QTw"},"source":["여러 문제점을 해결하였지만, SGD는 여전히 다음과 같은 두 가지의 문제점을 가지고 있습니다.\n","\n","1. Local Minima, 혹은 Saddle Point에 갇힐 가능성을 배제하지 못한다.\n","2. 모든 parameter에 대해서 동일한 step size를 주고 있다.\n","\n","단순히 2차함수가 아닌이상 해당 값이 global minima가 아닐 수 있다.\n","\n","우선, 1번 문제를 해결하고자 노력한 optimizer를 살펴봅시다."]},{"cell_type":"markdown","metadata":{"id":"SEPNjvaw7QTx"},"source":["## 2-1. Momentum (1964)"]},{"cell_type":"markdown","metadata":{"id":"Isjcnuap7QTx"},"source":["$$v_t \\leftarrow \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$$\n","$$\\theta \\leftarrow \\theta - v_t$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function, $0 < \\gamma < 1$\n","\n","새로운 파라미터는 파라미터네 vt를 뺀것과 같음 vt는 "]},{"cell_type":"markdown","metadata":{"id":"zLBvPzNv7QTy"},"source":["Momentum은 Local Minima, 혹은 Saddle Point에서 관성을 통해서 탈출할 수 있는 역할을 적용한 optimizer입니다. 또한, Osciliating(최적의 parameter에 다가가는 과정에서 진동하는 현상)이 SGD에 비해 덜 심하여, 비교적 안정적으로 global minimum으로 다가가는 모습을 보여줍니다. $\\gamma$는 decaying constant로, 일반적으로 $\\gamma = 0.9$의 값을 사용합니다. 이는 $(t-1)$기의 momentum $v_{t-1}$이 $t$기의 momentum $v_t$에 영향을 주는 정도를 의미합니다. (시간이 지날수록 영향력이 감소할 것임을 알 수 있습니다.)\n","\n","하지만 Momentum은 global minimum에 도착해서도 관성 때문에 정착하지 못하고(수렴하지 못한다) 그 주변에서 맴돈다는 문제점을 가지고 있습니다. 한참 뒤에 수렴함 이런 문제 존재"]},{"cell_type":"markdown","metadata":{"id":"kzpr7pt07QT0"},"source":["## 2-2. Nesterov Accelerated Gradient (NAG) (1983)"]},{"cell_type":"markdown","metadata":{"id":"cLlvtxVv7QT0"},"source":["$$v_t \\leftarrow \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta - \\gamma v_{t-1})$$\n","$$\\theta \\leftarrow \\theta - v_t$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function, $0 < \\gamma < 1$ (decaying constant)"]},{"cell_type":"markdown","metadata":{"id":"nsUx4Dez7QT1"},"source":["Momentum이 관성의 방향과 gradient의 방향을 각각 고려한 방식이었다면, NAG는 Momentum 방향에서 gradient를 구하는 방식입니다. 그리고 이러한 부분은 Momentum의 문제점(Global Minimum에서 정착하지 못한다는 점)을 해결해주었습니다. 즉, Momentum과 비교했을 때, NAG가 global minimum에서 조금 더 빨리 수렴하게 됩니다."]},{"cell_type":"markdown","metadata":{"id":"tK5RUgZc7QT1"},"source":["# 3. Adaptive Gradient 계열"]},{"cell_type":"markdown","metadata":{"id":"XwWMbhRm7QT1"},"source":["앞서 SGD가 다음과 같은 두 가지의 문제점을 가지고 있음을 이야기하였습니다.\n","\n","1. Local Minima, 혹은 Saddle Point에 갇힐 가능성을 배제하지 못한다.\n","2. 모든 parameter에 대해서 동일한 step size를 주고 있다.\n","\n","그리고 Momentum과 NAG가 1번 문제를 해결하고자 하였음을 확인하였습니다. 이제 2번 문제를 해결하기 위한 노력들을 확인해봅시다."]},{"cell_type":"markdown","metadata":{"id":"umPySr4c7QT2"},"source":["## 3-1. Adaptive Gradient (Adagrad) (2011)"]},{"cell_type":"markdown","metadata":{"id":"CBxGsn4D7QT2"},"source":["$$G_t = G_{t-1} + \\nabla_{\\theta_t} J(\\theta_t) \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$\\theta_{t+1} = \\theta_t - \\frac{\\eta} {\\sqrt{(G_t + \\epsilon)}} \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function, $\\odot$: Hadamard Product"]},{"cell_type":"markdown","metadata":{"id":"ZMf2OZXn7QT2"},"source":["Hadamard Product(혹은 Element-wise Product)는 일반적인 matrices 간의 곱이 아닌, 행렬의 각 원소 별 곱을 의미합니다. 따라서, Hadamard Product는 차원이 같은 matrices 간에서만 사용될 수 있습니다. Adagrad는 이러한 Hadamard Product를 채택하여 원소별로 step size를 계산을 하는 방식입니다. 즉, 동일한 learning rate이더라도 빠르게 수렴하는 부분은 step size를 작게, 천천히 수렴하는 부분은 step size를 크게 지정해줄 수 있는 것입니다. 하지만 $G_t$가 무한히 커지게 되는 구조로 되어 있기 때문에, adagrad는 training이 지속되면 학습의 결과가 제대로 반영되지 않는 문제점을 가지고 있습니다."]},{"cell_type":"markdown","metadata":{"id":"kgKK5P097QT3"},"source":["## 3-2. RMSProp"]},{"cell_type":"markdown","metadata":{"id":"afPPECce7QT3"},"source":["$$G_t = \\gamma G_{t-1} + (1 - \\gamma)\\nabla_{\\theta_t} J(\\theta_t) \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$\\theta_{t+1} = \\theta_t - \\frac{\\eta} {\\sqrt{(G_t + \\epsilon)}} \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","\n",", where $\\theta$: Parameter set of the model, $\\eta$: Learning Rate, $J(\\theta)$: Loss Function, $\\odot$: Hadamard Product, $0 < \\gamma < 1$ (decaying constant)"]},{"cell_type":"markdown","metadata":{"id":"CSydkvpK7QT3"},"source":["RMSProp은 Adagrad의 문제점($G_t$가 bounded되지 않아, 일정 정도 update가 진행되면 training이 제대로 이루어지지 않는다는 점)을 해결하기 위하여 등장하였습니다. RMSProp은 다른 optimizer들처럼 논문으로 소개되지 않고, Coursera 동영상 강의에서 공개되었습니다. RMSProp의 핵심은 지수가중평균(Exponentially Weighted Average), 혹은 지수이동평균(Exponentially Moving Average)에 있습니다. <br>\n","\n","Adagrad에 사용된 $G_t$는 단순히 gradient의 합으로 구성되었습니다. 그리고 이 점이 $G_t$를 무한히 크게 만들었습니다. 반면, RMSProp의 $G_t$는 이전에 더해진 gradient에는 decaying constant $\\gamma$를, 새로운 gradient에는 (1 - $\\gamma$) 곱하면서 더하는 구조로 되어 있고, 따라서 먼저 더해진 gradient에는 $\\gamma$가 더 많이 곱해지게 됩니다. 그리고 바로 이 점이 $G_t$가 무한히 커지는 것을 제한합니다. 또한, 이러한 RMSProp의 구조는 최근의 gradient가 이전의 gradient들에 비해 더 강한 영향력을 줄 수 있도록 만들어줍니다."]},{"cell_type":"markdown","metadata":{"id":"gBPt5NY97QT4"},"source":["## 3-3. Adadelta (2012)"]},{"cell_type":"markdown","metadata":{"id":"RjEqMl2-7QT5"},"source":["$$G_t = \\gamma G_{t-1} + \\nabla_{\\theta_t} J(\\theta_t) \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$\\Delta_{\\theta_t} = \\frac{\\sqrt{s_{t-1} + \\epsilon}} {\\sqrt{G_t + \\epsilon}} \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$s_t = \\gamma s_{t-1} + (1 - \\gamma) \\Delta_{\\theta_t} \\odot \\Delta_{\\theta_t}$$\n","\n","\n","$$\\theta_{t+1} = \\theta_t - \\Delta_{\\theta_t}$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function, $\\odot$: Hadamard Product, $0 < \\gamma < 1$ (decaying constant)"]},{"cell_type":"markdown","metadata":{"id":"vrZ4rlcm7QT6"},"source":["Adadelta는 Adagrad의 문제점($G_t$가 bounded되지 않아, 일정 정도 update가 진행되면 training이 제대로 이루어지지 않는다는 점)을 해결하기 위하여 등장하였습니다. RMSProp과 Adadelta는 거의 같은 시기에 개별적으로 연구된 것으로 보이나, Adadelta에는 RMSProp의 기법이 녹아들어가 있습니다. 또한, 문제점을 해결하기 위하여 Momentum의 기법을 활용한 흔적도 보입니다. 즉, 세 개의 optimizer가 한 데에 모인 셈이며, 이러한 측면에서는 RMSProp을 Adadelta의 특정 case라고 보아도 무방합니다.\n","\n","Adadelta의 특징은 다음과 같습니다.\n","\n","1. 기존의 optimizer는 단위(unit)가 맞지 않게 수식이 구성되어 있었는데, Adadelta는 단위를 보정하였다.\n","2. 다른 optimizer들과 달리, 초기 learning rate($\\eta$)를 지정하지 않는다.\n","\n","단위의 일치가 실제 학습에 도움이 되는지에 관해서는 이견이 존재합니다. 다만, 해당 방법을 고안하는 과정에서 Gradient Descent Algorithm에서 일반적으로 고려하는 First Order Condition에서 그치지 않고 Second Order Condition까지 고려하였으며, 이 과정에서 Hessian Matrix 등을 적극적으로 도입하였다는 점 등은 높이 평가할 만합니다. 물론 미분을 추가적으로 하는 만큼 계산 속도는 더 느려지게 되지만, 이를 통해 saddle point에 갇히는 문제를 해결할 수 있습니다. 즉, 부분적으로 SGD의 1번 문제점도 해결한 셈입니다."]},{"cell_type":"markdown","metadata":{"id":"kp6Ec3NH7QT7"},"source":["# 4. Adaptive Moment Estimator 계열"]},{"cell_type":"markdown","metadata":{"id":"5dnxbLmf7QT7"},"source":["앞서 SGD가 다음과 같은 두 가지의 문제점을 가지고 있음을 이야기하였습니다.\n","\n","1. Local Minima, 혹은 Saddle Point에 갇힐 가능성을 배제하지 못한다.\n","2. 모든 parameter에 대해서 동일한 step size를 주고 있다.\n","\n","그리고 Momentum과 NAG가 1번 문제, Adagrad, RMSProp, 그리고 Adadelta가 2번 문제를 해결하고자 하였음을 확인하였습니다. 지금부터는 이러한 노력들을 한 곳에 모아 SGD의 문제점을 최대한 제거하려고 노력한 optimizer들을 확인해봅시다."]},{"cell_type":"markdown","metadata":{"id":"QHPh8xfE7QT8"},"source":["## 4-1. Adaptive Moment Estimation (Adam) (2015)"]},{"cell_type":"markdown","metadata":{"id":"hK663ruq7QT8"},"source":["$$m_t = \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\nabla_{\\theta_t} J(\\theta_t) \\odot \\nabla_{\\theta_t} J(\\theta_t)$$\n","$$\\hat{m}_t = \\frac{m_t} {1 - \\beta_1^t}, \\quad \\hat{v}_t = \\frac{v_t} {1 - \\beta_2^t}$$\n","$$\\theta_{t+1} = \\theta_t - \\frac{\\eta} {\\sqrt{\\hat{v}_t + \\epsilon}} \\hat{m}_t$$\n","\n",", where $\\theta$: Parameter Set of the model, $\\eta$: Learning Rate, $J(\\cdot)$: Loss Function, $\\odot$: Hadamard Product, $0 < \\beta_1, \\beta_2 < 1$ (decaying constant)"]},{"cell_type":"markdown","metadata":{"id":"hzoS7cat7QT9"},"source":["Adam은 Momentum과 Adadelta(혹은 RMSProp)의 특성을 함께 물려받은 optimizer입니다. 이름의 moment는 두 개의 moment(gradient term을 가지고 있는 first moment $m_t$(mean)와 gradient의 square term을 가지고 있는 second moment $v_t$(uncentered variance))를 이용하는 데에서 비롯되었습니다. 저자들은 이 두 moment가 각각 평균 $0$, 분산 $1$(정확히는 $1$에 근접한 어떤 숫자 $\\beta_1$과 $\\beta_2$)로 biased되어 있다는 점을 인지하였고, 그래서 normalized된 $\\hat{m}_t$, $\\hat{v}_t$를 이용하기로 하였습니다. 참고로, 저자들은 $\\beta_1 = 0.9$, $\\beta_2 = 0.999$를 제안하고 있습니다."]},{"cell_type":"markdown","metadata":{"id":"mZt_sPiK7QT9"},"source":["## 4-2. AdaMax (2015)"]},{"cell_type":"markdown","metadata":{"id":"YGiHH1y9SbHh"},"source":["Adam은 $L_2$ norm에 기반한 optimizer였다면, Adamax는 $L_{\\infty}$에 기반한 optimizer입니다.  Adamax는 Adam 논문에 함께 발표되었습니다. 우선, Adam의 $v_t$를 다시 한 번 확인해보면 다음과 같습니다."]},{"cell_type":"markdown","metadata":{"id":"iJyywOV1TzrI"},"source":["$$v_t = \\beta_2 v_{t-1} + (1 - \\beta_2) \\nabla_{\\theta_t} J(\\theta_t) \\odot \\nabla_{\\theta_t} J(\\theta_t)$$"]},{"cell_type":"markdown","metadata":{"id":"7tip3R9zTznQ"},"source":["그리고 이를 $L_p$ norm에 관한 식으로 normalize해보면 다음과 같습니다. 편의상 $\\nabla_{\\theta_t} J(\\theta_t)$의 $p$회 Hadamard product를 $(\\nabla_{\\theta_t} J(\\theta_t))^p$로 표기하였습니다. 또한, 저자들은 이 과정에서 parameter $\\beta_2$도 $\\beta_2^p$로 변환하였습니다."]},{"cell_type":"markdown","metadata":{"id":"VJ7ZNRZdTziO"},"source":["$$v_t = \\beta_2^p v_{t-1} + (1 - \\beta_2^p) (\\nabla_{\\theta_t} J(\\theta_t))^p$$"]},{"cell_type":"markdown","metadata":{"id":"XXlV8iBdTzeI"},"source":["그리고 여기에서 $p$를 무한대로 보내면 다음과 같이 $u_t$를 정의할 수 있으며, 이 식의 $v_{t-1}$은 Adam에서 정의된 $L_2$ norm의 $v_t$와 동일합니다."]},{"cell_type":"markdown","metadata":{"id":"U8taVEbRVE_X"},"source":["$$\n","\\begin{aligned}\n","u_t &= \\beta_2^{\\infty} v_{t-1} + (1 - \\beta_2^{\\infty}) (\\nabla_{\\theta_t} J(\\theta_t))^{\\infty} \\\\\n","&= max({\\beta_2 \\cdot v_{t-1}, \\nabla_{\\theta_t} J(\\theta_t)})\n","\\end{aligned}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"6NQDcsW_VE2m"},"source":["Adamax의 parameter update는 이 $u_t$와 $\\hat{m_t}$를 기반으로 진행됩니다."]},{"cell_type":"markdown","metadata":{"id":"tNCYvnwIYeE_"},"source":["$$\\theta_{t+1} = \\theta_t - \\frac{\\eta} {u_t} \\hat{m}_t$$"]},{"cell_type":"markdown","metadata":{"id":"zvRriRmKGuCs"},"source":["## 4-3 그러면 Adam이 최고입니까?"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-26T11:40:52.481910Z","iopub.status.busy":"2021-10-26T11:40:52.481595Z","iopub.status.idle":"2021-10-26T11:40:52.487191Z","shell.execute_reply":"2021-10-26T11:40:52.486215Z","shell.execute_reply.started":"2021-10-26T11:40:52.481878Z"},"id":"lu5uRe6ZGuCs"},"source":["Adam 이후로도 optimizer에 관한 연구는 계속 진행되고 있으며, 저는 AdamW와 Rectified Adam을 선호하는 편입니다. 또한, 어떤 optimizer가 더 좋은 성능을 내는가에 관한 질문에 대해서는 정해진 답이 없으며, task에 따라 Adam 이전에 만들어진 optimizer가 더 좋은 성능을 보이기도 합니다. task마다 적합한 optimizer를 찾는 것 역시 하나의 과제입니다. 비록 Adam이 최고의 선택지라고 장담할 수는 없으나, 많은 상황에서 그럭저럭 무난한 성능을 보여주기 때문에 일반적으로는 Adam을 우선적으로 사용한 뒤에, 성능이 좋지 못하다고 판단되면 SGD나 RMSProp으로 변경하는 순으로 진행합니다."]},{"cell_type":"markdown","metadata":{"id":"MZG-Xbq97QUE"},"source":["# 5. Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"ajg_1Nbf7QUF"},"source":["<p align=\"center\">\n","  <img src=\"http://deeplearning.stanford.edu/wiki/images/6/6c/Convolution_schematic.gif\" alt=\"text\"/> </p>\n","\n","사진 출처: http://deeplearning.stanford.edu/wiki/images/"]},{"cell_type":"markdown","metadata":{"id":"lanwATGcGuCv"},"source":["## 5-1. CNN의 등장 배경"]},{"cell_type":"markdown","metadata":{"id":"LZ3jHe3kGuCv"},"source":["과제를 통해서 이미지를 Fully Connected Layer로 분류해보셨을텐데, 이러한 과정에는 다음과 같은 문제점이 뒤따릅니다.\n","\n","1. 높이(h), 너비(w), 채널(RGB)를 무시하고 한 줄로 펼쳐서 학습을 진행하기 때문에 공간 정보가 손실됩니다.\n","2. 모든 픽셀마다 weight를 주어야 하므로 이미지가 커질수록 weight가 기하급수적으로 많아집니다.\n","\n","CNN은이러한 문제점을 해결하고자 등장하였으며, 당연히 처음에는 이미지 분야에서 많이 사용되었습니다. (현재에는 다양한 분야에서 두루두루 사용됩니다.)"]},{"cell_type":"markdown","metadata":{"id":"e_pOU0D1GuCw"},"source":["## 5-2. CNN의 구조"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-26T13:56:49.727071Z","iopub.status.busy":"2021-10-26T13:56:49.726772Z","iopub.status.idle":"2021-10-26T13:56:49.731517Z","shell.execute_reply":"2021-10-26T13:56:49.730874Z","shell.execute_reply.started":"2021-10-26T13:56:49.727041Z"},"id":"vJFBYB-mGuCx"},"source":["<p align=\"center\">\n","  <img src=\"https://taewanmerepo.github.io/2018/01/cnn/head.png\" alt=\"text\"/> </p>\n","\n","사진 출처: http://taewan.kim/post/cnn/"]},{"cell_type":"markdown","metadata":{"id":"JSXPjHtRGuCx"},"source":["CNN은 크게 2개의 부분으로 구분지을 수 있습니다.\n","\n","1. Feature Extraction(Convolution, Pooling 등으로 이미지의 특성을 파악하는 부분)\n","2. Classification(추출된 특성을 기반으로 이미지를 분류하는 부분)\n","\n","즉, output 부분은 기존에 사용하던 FC Layer와 동일하다고 볼 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"JjOxnTJdGuCy"},"source":["## 5-3 Filter와 Kernel"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-26T14:02:31.775170Z","iopub.status.busy":"2021-10-26T14:02:31.774875Z","iopub.status.idle":"2021-10-26T14:02:31.780558Z","shell.execute_reply":"2021-10-26T14:02:31.779393Z","shell.execute_reply.started":"2021-10-26T14:02:31.775141Z"},"id":"Dqehzl-YGuCy"},"source":["<p align=\"center\">\n","  <img src=\"https://taewanmerepo.github.io/2018/01/cnn/conv.png\" alt=\"text\"/> </p>\n","  \n","<p align=\"center\">\n","  <img src=\"https://taewanmerepo.github.io/2018/01/cnn/filter.jpg\" alt=\"text\"/> </p>\n","\n","사진 출처: http://taewan.kim/post/cnn/"]},{"cell_type":"markdown","metadata":{"id":"PAKPU0wdGuCz"},"source":["convolution layer는 이미지를 특정 영역으로 제한하여 확인하는 방식을 사용합니다. 한 번에 확인할 픽셀의 크기를 kernel라고 하며, 일반적으로 $3 \\times 3$, $5 \\times 5$, $7 \\times 7$ 등 한 변의 크기가 홀수인 정사각형 형태로 지정을 합니다. 또한, filter는 kernel의 갯수(커널이 몇층인가? 보통 2의 배수로 표현)를 의미합니다. (한 filter 안의 각 kernel은 다른 값을 가질 수 있습니다.) 각 kernel은 이미지 상에서 움직이면서 Hadamard Product를 진행하며 feature extraction을 진행합니다."]},{"cell_type":"markdown","metadata":{"id":"ig44CN5HGuCz"},"source":["## 5-4. Stride와 Padding"]},{"cell_type":"markdown","metadata":{"id":"ArSCiALMGuC0"},"source":["stride는 한 번에 kernel이 움직이는 걸음의 수입니다. 얼마나 움직이는가? 앞서 본 이미지들은 모두 stride=1인 경우이며, 2, 3 등으로 stride를 조절할 수 있습니다. 당연히 손실되는 정보가 커지겠지만, 연산 속도에서 이점을 가질 수도 있습니다. padding은 convolution layer를 여러 번 거치면서 이미지가 필연적으로 작아지는 현상을 방지하기 위해서 이미지 주변에 0을 채워넣는 기법입니다. padding은 비교적 모서리 부분이 중앙 부분에 비해 연산이 더 적게 되는 점을 보완해주기도 합니다. 이론 상으로는 input data의 크기, kernel size와 stride, padding을 모두 고려해서 output data의 크기를 자연수로 맞춰주어야 하지만, 정확하게 계산이 맞아 떨어지지 않아도 프레임워크 상에서 어느 정도 조절해줍니다. 이에 관한 공식은 다음과 같습니다.\n","\n","$$O = \\frac{I - F + 2P} {S} + 1$$\n","\n","($O$: Output data의 크기, $I$: Input data의 크기, $F$: Kernel의 크기, $P$: Padding, $S$: Stride)"]},{"cell_type":"markdown","metadata":{"id":"xmOAFYQ7GuC0"},"source":["## 5-5. Pooling"]},{"cell_type":"markdown","metadata":{"id":"57nX5le7GuC1"},"source":["Pooling Layer는 위의 과정을 통해 Convolution Layer를 거친 결과(Feature Extraction을 통해 얻어진 정보, feature map이라고도 함)의 크기를 줄이면서 함축적으로 정보를 포함하도록 만들어주는 layer입니다. kernel과 마찬가지로 특정 영역마다 연산이 수행되는데, kernel과 다르게 일반적으로 연산 영역이 겹치지 않도록 설정합니다. (즉, stride와 pooling의 size를 동일하게 설정합니다.) 다양한 pooling 기법이 있으나, MaxPooling과 GlobalAveragePooling 정도가 많이 쓰이는 편입니다. 물론 이 역시 정답은 없습니다."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-26T14:42:15.734693Z","iopub.status.busy":"2021-10-26T14:42:15.734388Z","iopub.status.idle":"2021-10-26T14:42:15.739452Z","shell.execute_reply":"2021-10-26T14:42:15.738637Z","shell.execute_reply.started":"2021-10-26T14:42:15.734663Z"},"id":"_MoSQsGVGuC2"},"source":["<p align=\"center\">\n","  <img src=\"https://taewanmerepo.github.io/2018/02/cnn/maxpulling.png\" alt=\"text\"/> </p>\n","\n","사진 출처: http://taewan.kim/post/cnn/"]},{"cell_type":"markdown","metadata":{"id":"CJDWZn9lGuC2"},"source":["## 5-6. 구조를 다시 한 번 확인해봅시다."]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2021-10-26T14:43:45.541143Z","iopub.status.busy":"2021-10-26T14:43:45.540849Z","iopub.status.idle":"2021-10-26T14:43:45.545831Z","shell.execute_reply":"2021-10-26T14:43:45.545035Z","shell.execute_reply.started":"2021-10-26T14:43:45.541115Z"},"id":"Lqe7AiWMGuC2"},"source":["<p align=\"center\">\n","  <img src=\"https://taewanmerepo.github.io/2018/01/cnn/cnnexam.png\" alt=\"text\"/> </p>\n","\n","사진 출처: http://taewan.kim/post/cnn/"]},{"cell_type":"markdown","metadata":{"id":"w_Q-WFfxGuC3"},"source":["다음 시간에는 다음과 같은 부분들을 확인해보겠습니다.\n","\n","* 1<sup>st</sup> Competetion 안내 <br>\n","MNIST Dataset을 사용하여 진행될 예정입니다. 학회 가입 이전에 이미 해당 데이터를 다루어보신 분들도 계신다는 점을 인지하고 있고, 따라서 이를 감안하여 조 배정을 하였습니다.\n","\n","* CNN Model을 코드로 구현해보기 <br>\n","이론에 관한 내용들은 거의 다 다루었지만, 이와 코드 구현은 별개의 과정이므로, 이번 세션만 듣고 CNN 모델을 구성하는 것은 쉽지 않을 것입니다. <br>\n","다음 세션에서 간단한 CNN Model을 구성하는 방법을 확인해보겠습니다.\n","\n","* 간단한 팁 <br>\n","시간이 허락해준다면, 마지막에 0.1%라도 accuracy를 올릴 수 있는 방법에 관하여 이야기해보는 시간을 가질 계획입니다."]}]}