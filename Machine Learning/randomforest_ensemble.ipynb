{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "Session_5_Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgpzf_47uVAu"
      },
      "source": [
        "## 1. Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "oBSDk90CuVAu",
        "outputId": "d748d4f9-003a-4789-9981-3dfe5754c5da"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features= dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
        "cancer_df['target']= y_label\n",
        "cancer_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZAiZJn2gTxD",
        "outputId": "d94f5de4-f8e6-40aa-d3e3-fdd3a6b7539a"
      },
      "source": [
        "print(dataset.target_names)\n",
        "print(cancer_df.info())\n",
        "print(cancer_df['target'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n",
            "None\n",
            "1    357\n",
            "0    212\n",
            "Name: target, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O7Dxw0XjTjo",
        "outputId": "8ca60823-68c5-464a-df07-b8627f20028d"
      },
      "source": [
        "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
        "                                         test_size=0.2, random_state=156 )\n",
        "print(X_train.shape , X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30) (114, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck7X9V8iuVAw"
      },
      "source": [
        "**VotingClassifier로 개별모델은 로지스틱 회귀와 KNN을 보팅방식으로 결합하고 성능 비교**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iaWcr4GuVAw",
        "outputId": "4cc751bb-da9e-4b8c-b1b5-f95d91822e99"
      },
      "source": [
        "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
        "lr_clf = LogisticRegression()\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
        "\n",
        "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
        "vo_clf = VotingClassifier( estimators=[('LR',lr_clf),('KNN',knn_clf)] , voting='soft' )\n",
        "\n",
        "# VotingClassifier 학습/예측/평가. \n",
        "vo_clf.fit(X_train , y_train)\n",
        "pred = vo_clf.predict(X_test)\n",
        "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))\n",
        "\n",
        "# 개별 모델의 학습/예측/평가.\n",
        "classifiers = [lr_clf, knn_clf]\n",
        "for classifier in classifiers:\n",
        "    classifier.fit(X_train , y_train)\n",
        "    pred = classifier.predict(X_test)\n",
        "    class_name= classifier.__class__.__name__\n",
        "    print('{0} 정확도: {1:.4f}'.format(class_name, accuracy_score(y_test , pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Voting 분류기 정확도: 0.9474\n",
            "LogisticRegression 정확도: 0.9386\n",
            "KNeighborsClassifier 정확도: 0.9386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7Hny14GuVAw"
      },
      "source": [
        "## 2. Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ig55JguVAy"
      },
      "source": [
        "**학습/테스트 데이터로 분리하고 랜덤 포레스트로 학습/예측/평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxe9SNTuuVAy",
        "outputId": "d7af404f-aa8a-41e4-f6fb-7a5fb27c99e7"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label,\n",
        "                                         test_size=0.2, random_state=156 )\n",
        "\n",
        "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
        "rf_clf = RandomForestClassifier(random_state=0)\n",
        "rf_clf.fit(X_train , y_train)\n",
        "pred = rf_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test , pred)\n",
        "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "랜덤 포레스트 정확도: 0.9561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5llfQGIauVAy"
      },
      "source": [
        "**GridSearchCV 로 교차검증 및 하이퍼 파라미터 튜닝**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItTNulH6uVAy",
        "outputId": "37252563-3c69-4ef8-c572-b0939f42173a"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# 각 params의 값 적용\n",
        "params = {\n",
        "    'n_estimators':[100, 200, 300],\n",
        "    'max_depth' : [4, 6, 8], \n",
        "    'min_samples_leaf' : [4, 8, 12 ],\n",
        "    'min_samples_split' : [4, 8, 16]\n",
        "}\n",
        "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
        "rf_clf = RandomForestClassifier(random_state=0, n_jobs=-1)  # n_jobs=-1 : 모든 코어 사용\n",
        "grid_cv = GridSearchCV(rf_clf , param_grid=params , cv=5, n_jobs=-1 ) # cv : 교차검증에서 분할 개수\n",
        "grid_cv.fit(X_train , y_train)\n",
        "\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 4, 'n_estimators': 100}\n",
            "최고 예측 정확도: 0.9582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW9VsmiwuVAz",
        "outputId": "1f84fdfa-91c7-45d9-8601-fa2c624ca377"
      },
      "source": [
        "rf_clf1 = RandomForestClassifier(n_estimators=100, max_depth=6, min_samples_leaf = 4, \n",
        "                                min_samples_split=4, random_state=0)  # 최적 파라미터로 테스트\n",
        "rf_clf1.fit(X_train , y_train)\n",
        "pred = rf_clf1.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test , pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9474\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJBlOOiJuVAz"
      },
      "source": [
        "## 3 GBM(Gradient Boosting Machine)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tfMqPeIuVA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0349a52d-f7fe-4d2f-817a-a827620aec90"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
        "                                                    test_size=0.2 , random_state= 156)\n",
        "\n",
        "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
        "start_time = time.time()\n",
        "\n",
        "gb_clf = GradientBoostingClassifier(random_state=0)\n",
        "gb_clf.fit(X_train , y_train)\n",
        "gb_pred = gb_clf.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "\n",
        "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
        "print(\"GBM 수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GBM 정확도: 0.9561\n",
            "GBM 수행 시간: 0.4 초 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa51nqUvuVA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84975d1c-ff32-42bc-d188-0f504b06f208"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    'n_estimators':[100, 500],\n",
        "    'learning_rate' : [ 0.05, 0.1]\n",
        "}\n",
        "grid_cv = GridSearchCV(gb_clf , param_grid=params , cv=2 ,verbose=1)\n",
        "grid_cv.fit(X_train , y_train)\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'learning_rate': 0.1, 'n_estimators': 100}\n",
            "최고 예측 정확도: 0.9385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhTT-ZuWuVA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "cd5f664d-1d2c-4817-c8f5-9b3ad0e62cb4"
      },
      "source": [
        "scores_df = pd.DataFrame(grid_cv.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
        "          'split0_test_score', 'split1_test_score']]  # splitN_test_score폴드 세트 N번째의 성능 수치"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'learning_rate': 0.05, 'n_estimators': 100}</td>\n",
              "      <td>0.927525</td>\n",
              "      <td>4</td>\n",
              "      <td>0.903509</td>\n",
              "      <td>0.951542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'learning_rate': 0.05, 'n_estimators': 500}</td>\n",
              "      <td>0.936307</td>\n",
              "      <td>3</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.955947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'learning_rate': 0.1, 'n_estimators': 100}</td>\n",
              "      <td>0.938500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.921053</td>\n",
              "      <td>0.955947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'learning_rate': 0.1, 'n_estimators': 500}</td>\n",
              "      <td>0.938500</td>\n",
              "      <td>1</td>\n",
              "      <td>0.921053</td>\n",
              "      <td>0.955947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         params  ...  split1_test_score\n",
              "0  {'learning_rate': 0.05, 'n_estimators': 100}  ...           0.951542\n",
              "1  {'learning_rate': 0.05, 'n_estimators': 500}  ...           0.955947\n",
              "2   {'learning_rate': 0.1, 'n_estimators': 100}  ...           0.955947\n",
              "3   {'learning_rate': 0.1, 'n_estimators': 500}  ...           0.955947\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAPpwwfHuVA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15931550-7981-4393-f4d0-ea81ea615296"
      },
      "source": [
        "gb_pred = grid_cv.best_estimator_.predict(X_test)\n",
        "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
        "print('GBM 정확도: {0:.4f}'.format(gb_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GBM 정확도: 0.9561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUrTCfkVkFH6"
      },
      "source": [
        "## 4. XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "0cA-Fhorb29R",
        "outputId": "cef0d912-e50d-44f9-b50a-d8788d794b97"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features= dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
        "cancer_df['target']= y_label\n",
        "cancer_df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGIgC10DjFC6"
      },
      "source": [
        "# 넘파이 형태의 학습 데이터 세트와 테스트 데이터를 DMatrix로 변환\n",
        "dtrain = xgb.DMatrix(data=X_train , label=y_train)\n",
        "dtest = xgb.DMatrix(data=X_test , label=y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC-_kTYAjyY1"
      },
      "source": [
        "# max_depth = 3, 학습률은 0.1, 예제가 이진분류이므로 목적함수(objective)는 binary:logistic(이진 로지스틱)\n",
        "# 오류함수의 평가성능지표는 logloss\n",
        "# 조기중단을 위한 최소 반복횟수는 100\n",
        "# 부스팅 반복횟수는 400\n",
        "params = { 'max_depth':3,\n",
        "           'eta': 0.1,\n",
        "           'objective':'binary:logistic',\n",
        "           'eval_metric':'logloss',\n",
        "           'early_stoppings':100\n",
        "        }\n",
        "num_rounds = 400"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flg5OzPgj0Zv",
        "outputId": "114de497-d32b-48b2-ca8a-ad6bf6a4c095"
      },
      "source": [
        "# train 데이터 셋은 ‘train’ , evaluation(test) 데이터 셋은 ‘eval’ 로 명기합니다. \n",
        "wlist = [(dtrain,'train'),(dtest,'eval') ]\n",
        "# 하이퍼 파라미터와 early stopping 파라미터를 train( ) 함수의 파라미터로 전달\n",
        "# xgboost가 반복 시마다 evals에 표시된 데이터 세트에 대해 평가 지표를 출력\n",
        "xgb_model = xgb.train(params = params , dtrain=dtrain , num_boost_round=num_rounds , evals=wlist )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-logloss:0.609688\teval-logloss:0.61352\n",
            "[1]\ttrain-logloss:0.540803\teval-logloss:0.547843\n",
            "[2]\ttrain-logloss:0.483753\teval-logloss:0.494248\n",
            "[3]\ttrain-logloss:0.434457\teval-logloss:0.447986\n",
            "[4]\ttrain-logloss:0.39055\teval-logloss:0.409109\n",
            "[5]\ttrain-logloss:0.354146\teval-logloss:0.374977\n",
            "[6]\ttrain-logloss:0.321222\teval-logloss:0.345714\n",
            "[7]\ttrain-logloss:0.292593\teval-logloss:0.320529\n",
            "[8]\ttrain-logloss:0.267467\teval-logloss:0.29721\n",
            "[9]\ttrain-logloss:0.245153\teval-logloss:0.277991\n",
            "[10]\ttrain-logloss:0.225694\teval-logloss:0.260302\n",
            "[11]\ttrain-logloss:0.207938\teval-logloss:0.246037\n",
            "[12]\ttrain-logloss:0.192184\teval-logloss:0.231556\n",
            "[13]\ttrain-logloss:0.177916\teval-logloss:0.22005\n",
            "[14]\ttrain-logloss:0.165222\teval-logloss:0.208572\n",
            "[15]\ttrain-logloss:0.153622\teval-logloss:0.199993\n",
            "[16]\ttrain-logloss:0.14333\teval-logloss:0.190118\n",
            "[17]\ttrain-logloss:0.133985\teval-logloss:0.181818\n",
            "[18]\ttrain-logloss:0.125599\teval-logloss:0.174729\n",
            "[19]\ttrain-logloss:0.117286\teval-logloss:0.167657\n",
            "[20]\ttrain-logloss:0.109688\teval-logloss:0.158202\n",
            "[21]\ttrain-logloss:0.102975\teval-logloss:0.154725\n",
            "[22]\ttrain-logloss:0.097067\teval-logloss:0.148947\n",
            "[23]\ttrain-logloss:0.091428\teval-logloss:0.143308\n",
            "[24]\ttrain-logloss:0.086335\teval-logloss:0.136344\n",
            "[25]\ttrain-logloss:0.081311\teval-logloss:0.132778\n",
            "[26]\ttrain-logloss:0.076857\teval-logloss:0.127912\n",
            "[27]\ttrain-logloss:0.072836\teval-logloss:0.125263\n",
            "[28]\ttrain-logloss:0.069248\teval-logloss:0.119978\n",
            "[29]\ttrain-logloss:0.065549\teval-logloss:0.116412\n",
            "[30]\ttrain-logloss:0.062414\teval-logloss:0.114502\n",
            "[31]\ttrain-logloss:0.059591\teval-logloss:0.112572\n",
            "[32]\ttrain-logloss:0.057096\teval-logloss:0.11154\n",
            "[33]\ttrain-logloss:0.054407\teval-logloss:0.108681\n",
            "[34]\ttrain-logloss:0.052036\teval-logloss:0.106681\n",
            "[35]\ttrain-logloss:0.049751\teval-logloss:0.104207\n",
            "[36]\ttrain-logloss:0.04775\teval-logloss:0.102962\n",
            "[37]\ttrain-logloss:0.045853\teval-logloss:0.100576\n",
            "[38]\ttrain-logloss:0.044015\teval-logloss:0.098683\n",
            "[39]\ttrain-logloss:0.042263\teval-logloss:0.096444\n",
            "[40]\ttrain-logloss:0.040649\teval-logloss:0.095869\n",
            "[41]\ttrain-logloss:0.039126\teval-logloss:0.094242\n",
            "[42]\ttrain-logloss:0.037377\teval-logloss:0.094715\n",
            "[43]\ttrain-logloss:0.036106\teval-logloss:0.094272\n",
            "[44]\ttrain-logloss:0.034941\teval-logloss:0.093894\n",
            "[45]\ttrain-logloss:0.033654\teval-logloss:0.094184\n",
            "[46]\ttrain-logloss:0.032528\teval-logloss:0.09402\n",
            "[47]\ttrain-logloss:0.031485\teval-logloss:0.09236\n",
            "[48]\ttrain-logloss:0.030389\teval-logloss:0.093012\n",
            "[49]\ttrain-logloss:0.029467\teval-logloss:0.091273\n",
            "[50]\ttrain-logloss:0.028545\teval-logloss:0.090051\n",
            "[51]\ttrain-logloss:0.027525\teval-logloss:0.089605\n",
            "[52]\ttrain-logloss:0.026555\teval-logloss:0.089577\n",
            "[53]\ttrain-logloss:0.025682\teval-logloss:0.090703\n",
            "[54]\ttrain-logloss:0.025004\teval-logloss:0.089579\n",
            "[55]\ttrain-logloss:0.024297\teval-logloss:0.090357\n",
            "[56]\ttrain-logloss:0.023574\teval-logloss:0.091587\n",
            "[57]\ttrain-logloss:0.022965\teval-logloss:0.091527\n",
            "[58]\ttrain-logloss:0.022488\teval-logloss:0.091986\n",
            "[59]\ttrain-logloss:0.021854\teval-logloss:0.091951\n",
            "[60]\ttrain-logloss:0.021316\teval-logloss:0.091939\n",
            "[61]\ttrain-logloss:0.020794\teval-logloss:0.091461\n",
            "[62]\ttrain-logloss:0.020218\teval-logloss:0.090311\n",
            "[63]\ttrain-logloss:0.019701\teval-logloss:0.089407\n",
            "[64]\ttrain-logloss:0.01918\teval-logloss:0.089719\n",
            "[65]\ttrain-logloss:0.018724\teval-logloss:0.089743\n",
            "[66]\ttrain-logloss:0.018325\teval-logloss:0.089622\n",
            "[67]\ttrain-logloss:0.017867\teval-logloss:0.088734\n",
            "[68]\ttrain-logloss:0.017598\teval-logloss:0.088621\n",
            "[69]\ttrain-logloss:0.017243\teval-logloss:0.089739\n",
            "[70]\ttrain-logloss:0.01688\teval-logloss:0.089981\n",
            "[71]\ttrain-logloss:0.016641\teval-logloss:0.089782\n",
            "[72]\ttrain-logloss:0.016287\teval-logloss:0.089584\n",
            "[73]\ttrain-logloss:0.015983\teval-logloss:0.089533\n",
            "[74]\ttrain-logloss:0.015658\teval-logloss:0.088748\n",
            "[75]\ttrain-logloss:0.015393\teval-logloss:0.088597\n",
            "[76]\ttrain-logloss:0.015151\teval-logloss:0.08812\n",
            "[77]\ttrain-logloss:0.01488\teval-logloss:0.088396\n",
            "[78]\ttrain-logloss:0.014637\teval-logloss:0.088736\n",
            "[79]\ttrain-logloss:0.014491\teval-logloss:0.088153\n",
            "[80]\ttrain-logloss:0.014185\teval-logloss:0.087577\n",
            "[81]\ttrain-logloss:0.014005\teval-logloss:0.087412\n",
            "[82]\ttrain-logloss:0.013772\teval-logloss:0.08849\n",
            "[83]\ttrain-logloss:0.013568\teval-logloss:0.088575\n",
            "[84]\ttrain-logloss:0.013414\teval-logloss:0.08807\n",
            "[85]\ttrain-logloss:0.013253\teval-logloss:0.087641\n",
            "[86]\ttrain-logloss:0.013109\teval-logloss:0.087416\n",
            "[87]\ttrain-logloss:0.012926\teval-logloss:0.087611\n",
            "[88]\ttrain-logloss:0.012714\teval-logloss:0.087065\n",
            "[89]\ttrain-logloss:0.012544\teval-logloss:0.08727\n",
            "[90]\ttrain-logloss:0.012353\teval-logloss:0.087161\n",
            "[91]\ttrain-logloss:0.012226\teval-logloss:0.086962\n",
            "[92]\ttrain-logloss:0.012065\teval-logloss:0.087166\n",
            "[93]\ttrain-logloss:0.011927\teval-logloss:0.087067\n",
            "[94]\ttrain-logloss:0.011821\teval-logloss:0.086592\n",
            "[95]\ttrain-logloss:0.011649\teval-logloss:0.086116\n",
            "[96]\ttrain-logloss:0.011482\teval-logloss:0.087139\n",
            "[97]\ttrain-logloss:0.01136\teval-logloss:0.086768\n",
            "[98]\ttrain-logloss:0.011239\teval-logloss:0.086694\n",
            "[99]\ttrain-logloss:0.011132\teval-logloss:0.086547\n",
            "[100]\ttrain-logloss:0.011002\teval-logloss:0.086498\n",
            "[101]\ttrain-logloss:0.010852\teval-logloss:0.08641\n",
            "[102]\ttrain-logloss:0.010755\teval-logloss:0.086288\n",
            "[103]\ttrain-logloss:0.010636\teval-logloss:0.086258\n",
            "[104]\ttrain-logloss:0.0105\teval-logloss:0.086835\n",
            "[105]\ttrain-logloss:0.010395\teval-logloss:0.086767\n",
            "[106]\ttrain-logloss:0.010305\teval-logloss:0.087321\n",
            "[107]\ttrain-logloss:0.010197\teval-logloss:0.087304\n",
            "[108]\ttrain-logloss:0.010072\teval-logloss:0.08728\n",
            "[109]\ttrain-logloss:0.01\teval-logloss:0.087298\n",
            "[110]\ttrain-logloss:0.009914\teval-logloss:0.087289\n",
            "[111]\ttrain-logloss:0.009798\teval-logloss:0.088002\n",
            "[112]\ttrain-logloss:0.00971\teval-logloss:0.087936\n",
            "[113]\ttrain-logloss:0.009628\teval-logloss:0.087843\n",
            "[114]\ttrain-logloss:0.009558\teval-logloss:0.088066\n",
            "[115]\ttrain-logloss:0.009483\teval-logloss:0.087649\n",
            "[116]\ttrain-logloss:0.009416\teval-logloss:0.087298\n",
            "[117]\ttrain-logloss:0.009306\teval-logloss:0.087799\n",
            "[118]\ttrain-logloss:0.009228\teval-logloss:0.087751\n",
            "[119]\ttrain-logloss:0.009154\teval-logloss:0.08768\n",
            "[120]\ttrain-logloss:0.009118\teval-logloss:0.087626\n",
            "[121]\ttrain-logloss:0.009016\teval-logloss:0.08757\n",
            "[122]\ttrain-logloss:0.008972\teval-logloss:0.087547\n",
            "[123]\ttrain-logloss:0.008904\teval-logloss:0.087156\n",
            "[124]\ttrain-logloss:0.008837\teval-logloss:0.08767\n",
            "[125]\ttrain-logloss:0.008803\teval-logloss:0.087737\n",
            "[126]\ttrain-logloss:0.008709\teval-logloss:0.088275\n",
            "[127]\ttrain-logloss:0.008645\teval-logloss:0.088309\n",
            "[128]\ttrain-logloss:0.008613\teval-logloss:0.088266\n",
            "[129]\ttrain-logloss:0.008555\teval-logloss:0.087886\n",
            "[130]\ttrain-logloss:0.008463\teval-logloss:0.088861\n",
            "[131]\ttrain-logloss:0.008416\teval-logloss:0.088675\n",
            "[132]\ttrain-logloss:0.008385\teval-logloss:0.088743\n",
            "[133]\ttrain-logloss:0.0083\teval-logloss:0.089218\n",
            "[134]\ttrain-logloss:0.00827\teval-logloss:0.089179\n",
            "[135]\ttrain-logloss:0.008218\teval-logloss:0.088821\n",
            "[136]\ttrain-logloss:0.008157\teval-logloss:0.088512\n",
            "[137]\ttrain-logloss:0.008076\teval-logloss:0.08848\n",
            "[138]\ttrain-logloss:0.008047\teval-logloss:0.088386\n",
            "[139]\ttrain-logloss:0.007973\teval-logloss:0.089145\n",
            "[140]\ttrain-logloss:0.007946\teval-logloss:0.08911\n",
            "[141]\ttrain-logloss:0.007898\teval-logloss:0.088765\n",
            "[142]\ttrain-logloss:0.007872\teval-logloss:0.088678\n",
            "[143]\ttrain-logloss:0.007847\teval-logloss:0.088389\n",
            "[144]\ttrain-logloss:0.007776\teval-logloss:0.089271\n",
            "[145]\ttrain-logloss:0.007752\teval-logloss:0.089238\n",
            "[146]\ttrain-logloss:0.007728\teval-logloss:0.089139\n",
            "[147]\ttrain-logloss:0.007689\teval-logloss:0.088907\n",
            "[148]\ttrain-logloss:0.007621\teval-logloss:0.089416\n",
            "[149]\ttrain-logloss:0.007598\teval-logloss:0.089388\n",
            "[150]\ttrain-logloss:0.007575\teval-logloss:0.089108\n",
            "[151]\ttrain-logloss:0.007521\teval-logloss:0.088735\n",
            "[152]\ttrain-logloss:0.007498\teval-logloss:0.088717\n",
            "[153]\ttrain-logloss:0.007464\teval-logloss:0.088484\n",
            "[154]\ttrain-logloss:0.00741\teval-logloss:0.088471\n",
            "[155]\ttrain-logloss:0.007389\teval-logloss:0.088545\n",
            "[156]\ttrain-logloss:0.007367\teval-logloss:0.088521\n",
            "[157]\ttrain-logloss:0.007345\teval-logloss:0.088547\n",
            "[158]\ttrain-logloss:0.007323\teval-logloss:0.088275\n",
            "[159]\ttrain-logloss:0.007303\teval-logloss:0.0883\n",
            "[160]\ttrain-logloss:0.007282\teval-logloss:0.08828\n",
            "[161]\ttrain-logloss:0.007261\teval-logloss:0.088013\n",
            "[162]\ttrain-logloss:0.007241\teval-logloss:0.087758\n",
            "[163]\ttrain-logloss:0.007221\teval-logloss:0.087784\n",
            "[164]\ttrain-logloss:0.0072\teval-logloss:0.087777\n",
            "[165]\ttrain-logloss:0.00718\teval-logloss:0.087517\n",
            "[166]\ttrain-logloss:0.007161\teval-logloss:0.087542\n",
            "[167]\ttrain-logloss:0.007142\teval-logloss:0.087642\n",
            "[168]\ttrain-logloss:0.007122\teval-logloss:0.08739\n",
            "[169]\ttrain-logloss:0.007103\teval-logloss:0.087377\n",
            "[170]\ttrain-logloss:0.007084\teval-logloss:0.087298\n",
            "[171]\ttrain-logloss:0.007065\teval-logloss:0.087368\n",
            "[172]\ttrain-logloss:0.007047\teval-logloss:0.087395\n",
            "[173]\ttrain-logloss:0.007028\teval-logloss:0.087385\n",
            "[174]\ttrain-logloss:0.007009\teval-logloss:0.087132\n",
            "[175]\ttrain-logloss:0.006991\teval-logloss:0.087159\n",
            "[176]\ttrain-logloss:0.006973\teval-logloss:0.086955\n",
            "[177]\ttrain-logloss:0.006955\teval-logloss:0.087053\n",
            "[178]\ttrain-logloss:0.006937\teval-logloss:0.08697\n",
            "[179]\ttrain-logloss:0.00692\teval-logloss:0.086973\n",
            "[180]\ttrain-logloss:0.006901\teval-logloss:0.087038\n",
            "[181]\ttrain-logloss:0.006884\teval-logloss:0.086799\n",
            "[182]\ttrain-logloss:0.006866\teval-logloss:0.086826\n",
            "[183]\ttrain-logloss:0.006849\teval-logloss:0.086582\n",
            "[184]\ttrain-logloss:0.006831\teval-logloss:0.086588\n",
            "[185]\ttrain-logloss:0.006815\teval-logloss:0.086614\n",
            "[186]\ttrain-logloss:0.006798\teval-logloss:0.086372\n",
            "[187]\ttrain-logloss:0.006781\teval-logloss:0.086369\n",
            "[188]\ttrain-logloss:0.006764\teval-logloss:0.086297\n",
            "[189]\ttrain-logloss:0.006747\teval-logloss:0.086104\n",
            "[190]\ttrain-logloss:0.00673\teval-logloss:0.086023\n",
            "[191]\ttrain-logloss:0.006714\teval-logloss:0.08605\n",
            "[192]\ttrain-logloss:0.006698\teval-logloss:0.086149\n",
            "[193]\ttrain-logloss:0.006682\teval-logloss:0.085916\n",
            "[194]\ttrain-logloss:0.006666\teval-logloss:0.085915\n",
            "[195]\ttrain-logloss:0.00665\teval-logloss:0.085984\n",
            "[196]\ttrain-logloss:0.006634\teval-logloss:0.086012\n",
            "[197]\ttrain-logloss:0.006618\teval-logloss:0.085922\n",
            "[198]\ttrain-logloss:0.006603\teval-logloss:0.085853\n",
            "[199]\ttrain-logloss:0.006587\teval-logloss:0.085874\n",
            "[200]\ttrain-logloss:0.006572\teval-logloss:0.085888\n",
            "[201]\ttrain-logloss:0.006556\teval-logloss:0.08595\n",
            "[202]\ttrain-logloss:0.006542\teval-logloss:0.08573\n",
            "[203]\ttrain-logloss:0.006527\teval-logloss:0.08573\n",
            "[204]\ttrain-logloss:0.006512\teval-logloss:0.085753\n",
            "[205]\ttrain-logloss:0.006497\teval-logloss:0.085821\n",
            "[206]\ttrain-logloss:0.006483\teval-logloss:0.08584\n",
            "[207]\ttrain-logloss:0.006469\teval-logloss:0.085776\n",
            "[208]\ttrain-logloss:0.006455\teval-logloss:0.085686\n",
            "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
            "[210]\ttrain-logloss:0.006427\teval-logloss:0.085806\n",
            "[211]\ttrain-logloss:0.006413\teval-logloss:0.085593\n",
            "[212]\ttrain-logloss:0.006399\teval-logloss:0.085801\n",
            "[213]\ttrain-logloss:0.006385\teval-logloss:0.085807\n",
            "[214]\ttrain-logloss:0.006372\teval-logloss:0.085744\n",
            "[215]\ttrain-logloss:0.006359\teval-logloss:0.085658\n",
            "[216]\ttrain-logloss:0.006345\teval-logloss:0.085843\n",
            "[217]\ttrain-logloss:0.006332\teval-logloss:0.085632\n",
            "[218]\ttrain-logloss:0.006319\teval-logloss:0.085726\n",
            "[219]\ttrain-logloss:0.006306\teval-logloss:0.085783\n",
            "[220]\ttrain-logloss:0.006293\teval-logloss:0.085791\n",
            "[221]\ttrain-logloss:0.00628\teval-logloss:0.085817\n",
            "[222]\ttrain-logloss:0.006268\teval-logloss:0.085757\n",
            "[223]\ttrain-logloss:0.006255\teval-logloss:0.085674\n",
            "[224]\ttrain-logloss:0.006242\teval-logloss:0.08586\n",
            "[225]\ttrain-logloss:0.00623\teval-logloss:0.085871\n",
            "[226]\ttrain-logloss:0.006218\teval-logloss:0.085927\n",
            "[227]\ttrain-logloss:0.006206\teval-logloss:0.085954\n",
            "[228]\ttrain-logloss:0.006194\teval-logloss:0.085874\n",
            "[229]\ttrain-logloss:0.006182\teval-logloss:0.086057\n",
            "[230]\ttrain-logloss:0.00617\teval-logloss:0.086002\n",
            "[231]\ttrain-logloss:0.006158\teval-logloss:0.085922\n",
            "[232]\ttrain-logloss:0.006147\teval-logloss:0.086102\n",
            "[233]\ttrain-logloss:0.006135\teval-logloss:0.086115\n",
            "[234]\ttrain-logloss:0.006124\teval-logloss:0.086169\n",
            "[235]\ttrain-logloss:0.006112\teval-logloss:0.086263\n",
            "[236]\ttrain-logloss:0.006101\teval-logloss:0.086291\n",
            "[237]\ttrain-logloss:0.00609\teval-logloss:0.086217\n",
            "[238]\ttrain-logloss:0.006079\teval-logloss:0.086395\n",
            "[239]\ttrain-logloss:0.006068\teval-logloss:0.086342\n",
            "[240]\ttrain-logloss:0.006057\teval-logloss:0.08618\n",
            "[241]\ttrain-logloss:0.006046\teval-logloss:0.086195\n",
            "[242]\ttrain-logloss:0.006036\teval-logloss:0.086248\n",
            "[243]\ttrain-logloss:0.006025\teval-logloss:0.086263\n",
            "[244]\ttrain-logloss:0.006014\teval-logloss:0.086293\n",
            "[245]\ttrain-logloss:0.006004\teval-logloss:0.086222\n",
            "[246]\ttrain-logloss:0.005993\teval-logloss:0.086398\n",
            "[247]\ttrain-logloss:0.005983\teval-logloss:0.086347\n",
            "[248]\ttrain-logloss:0.005972\teval-logloss:0.086276\n",
            "[249]\ttrain-logloss:0.005962\teval-logloss:0.086448\n",
            "[250]\ttrain-logloss:0.005952\teval-logloss:0.086294\n",
            "[251]\ttrain-logloss:0.005942\teval-logloss:0.086312\n",
            "[252]\ttrain-logloss:0.005932\teval-logloss:0.086364\n",
            "[253]\ttrain-logloss:0.005922\teval-logloss:0.086394\n",
            "[254]\ttrain-logloss:0.005912\teval-logloss:0.08649\n",
            "[255]\ttrain-logloss:0.005903\teval-logloss:0.086441\n",
            "[256]\ttrain-logloss:0.005893\teval-logloss:0.08629\n",
            "[257]\ttrain-logloss:0.005883\teval-logloss:0.086459\n",
            "[258]\ttrain-logloss:0.005874\teval-logloss:0.086391\n",
            "[259]\ttrain-logloss:0.005864\teval-logloss:0.086441\n",
            "[260]\ttrain-logloss:0.005855\teval-logloss:0.086461\n",
            "[261]\ttrain-logloss:0.005845\teval-logloss:0.086491\n",
            "[262]\ttrain-logloss:0.005836\teval-logloss:0.086445\n",
            "[263]\ttrain-logloss:0.005827\teval-logloss:0.086466\n",
            "[264]\ttrain-logloss:0.005818\teval-logloss:0.086319\n",
            "[265]\ttrain-logloss:0.005809\teval-logloss:0.086488\n",
            "[266]\ttrain-logloss:0.0058\teval-logloss:0.086538\n",
            "[267]\ttrain-logloss:0.005791\teval-logloss:0.086471\n",
            "[268]\ttrain-logloss:0.005782\teval-logloss:0.086501\n",
            "[269]\ttrain-logloss:0.005773\teval-logloss:0.086522\n",
            "[270]\ttrain-logloss:0.005764\teval-logloss:0.086689\n",
            "[271]\ttrain-logloss:0.005755\teval-logloss:0.086738\n",
            "[272]\ttrain-logloss:0.005747\teval-logloss:0.086829\n",
            "[273]\ttrain-logloss:0.005738\teval-logloss:0.086684\n",
            "[274]\ttrain-logloss:0.005729\teval-logloss:0.08664\n",
            "[275]\ttrain-logloss:0.005721\teval-logloss:0.086496\n",
            "[276]\ttrain-logloss:0.005712\teval-logloss:0.086355\n",
            "[277]\ttrain-logloss:0.005704\teval-logloss:0.086519\n",
            "[278]\ttrain-logloss:0.005696\teval-logloss:0.086567\n",
            "[279]\ttrain-logloss:0.005687\teval-logloss:0.08659\n",
            "[280]\ttrain-logloss:0.005679\teval-logloss:0.086679\n",
            "[281]\ttrain-logloss:0.005671\teval-logloss:0.086637\n",
            "[282]\ttrain-logloss:0.005663\teval-logloss:0.086499\n",
            "[283]\ttrain-logloss:0.005655\teval-logloss:0.086356\n",
            "[284]\ttrain-logloss:0.005646\teval-logloss:0.086405\n",
            "[285]\ttrain-logloss:0.005639\teval-logloss:0.086429\n",
            "[286]\ttrain-logloss:0.005631\teval-logloss:0.086456\n",
            "[287]\ttrain-logloss:0.005623\teval-logloss:0.086504\n",
            "[288]\ttrain-logloss:0.005615\teval-logloss:0.08637\n",
            "[289]\ttrain-logloss:0.005608\teval-logloss:0.086457\n",
            "[290]\ttrain-logloss:0.0056\teval-logloss:0.086453\n",
            "[291]\ttrain-logloss:0.005593\teval-logloss:0.086322\n",
            "[292]\ttrain-logloss:0.005585\teval-logloss:0.086284\n",
            "[293]\ttrain-logloss:0.005577\teval-logloss:0.086148\n",
            "[294]\ttrain-logloss:0.00557\teval-logloss:0.086196\n",
            "[295]\ttrain-logloss:0.005563\teval-logloss:0.086221\n",
            "[296]\ttrain-logloss:0.005556\teval-logloss:0.086308\n",
            "[297]\ttrain-logloss:0.005548\teval-logloss:0.086178\n",
            "[298]\ttrain-logloss:0.005541\teval-logloss:0.086263\n",
            "[299]\ttrain-logloss:0.005534\teval-logloss:0.086131\n",
            "[300]\ttrain-logloss:0.005526\teval-logloss:0.086179\n",
            "[301]\ttrain-logloss:0.005519\teval-logloss:0.086052\n",
            "[302]\ttrain-logloss:0.005512\teval-logloss:0.086016\n",
            "[303]\ttrain-logloss:0.005505\teval-logloss:0.086101\n",
            "[304]\ttrain-logloss:0.005498\teval-logloss:0.085977\n",
            "[305]\ttrain-logloss:0.005491\teval-logloss:0.086059\n",
            "[306]\ttrain-logloss:0.005484\teval-logloss:0.085971\n",
            "[307]\ttrain-logloss:0.005478\teval-logloss:0.085998\n",
            "[308]\ttrain-logloss:0.005471\teval-logloss:0.085998\n",
            "[309]\ttrain-logloss:0.005464\teval-logloss:0.085877\n",
            "[310]\ttrain-logloss:0.005457\teval-logloss:0.085923\n",
            "[311]\ttrain-logloss:0.00545\teval-logloss:0.085948\n",
            "[312]\ttrain-logloss:0.005444\teval-logloss:0.086028\n",
            "[313]\ttrain-logloss:0.005437\teval-logloss:0.086112\n",
            "[314]\ttrain-logloss:0.00543\teval-logloss:0.085989\n",
            "[315]\ttrain-logloss:0.005424\teval-logloss:0.085903\n",
            "[316]\ttrain-logloss:0.005417\teval-logloss:0.085949\n",
            "[317]\ttrain-logloss:0.005411\teval-logloss:0.085977\n",
            "[318]\ttrain-logloss:0.005404\teval-logloss:0.086002\n",
            "[319]\ttrain-logloss:0.005398\teval-logloss:0.085883\n",
            "[320]\ttrain-logloss:0.005392\teval-logloss:0.085967\n",
            "[321]\ttrain-logloss:0.005385\teval-logloss:0.086046\n",
            "[322]\ttrain-logloss:0.005379\teval-logloss:0.086091\n",
            "[323]\ttrain-logloss:0.005373\teval-logloss:0.085977\n",
            "[324]\ttrain-logloss:0.005366\teval-logloss:0.085978\n",
            "[325]\ttrain-logloss:0.00536\teval-logloss:0.085896\n",
            "[326]\ttrain-logloss:0.005354\teval-logloss:0.08578\n",
            "[327]\ttrain-logloss:0.005348\teval-logloss:0.085857\n",
            "[328]\ttrain-logloss:0.005342\teval-logloss:0.085939\n",
            "[329]\ttrain-logloss:0.005336\teval-logloss:0.085825\n",
            "[330]\ttrain-logloss:0.00533\teval-logloss:0.085869\n",
            "[331]\ttrain-logloss:0.005324\teval-logloss:0.085893\n",
            "[332]\ttrain-logloss:0.005318\teval-logloss:0.085922\n",
            "[333]\ttrain-logloss:0.005312\teval-logloss:0.085842\n",
            "[334]\ttrain-logloss:0.005306\teval-logloss:0.085735\n",
            "[335]\ttrain-logloss:0.0053\teval-logloss:0.085816\n",
            "[336]\ttrain-logloss:0.005294\teval-logloss:0.085892\n",
            "[337]\ttrain-logloss:0.005288\teval-logloss:0.085936\n",
            "[338]\ttrain-logloss:0.005283\teval-logloss:0.08583\n",
            "[339]\ttrain-logloss:0.005277\teval-logloss:0.085909\n",
            "[340]\ttrain-logloss:0.005271\teval-logloss:0.085831\n",
            "[341]\ttrain-logloss:0.005265\teval-logloss:0.085727\n",
            "[342]\ttrain-logloss:0.00526\teval-logloss:0.085678\n",
            "[343]\ttrain-logloss:0.005254\teval-logloss:0.085721\n",
            "[344]\ttrain-logloss:0.005249\teval-logloss:0.085796\n",
            "[345]\ttrain-logloss:0.005243\teval-logloss:0.085819\n",
            "[346]\ttrain-logloss:0.005237\teval-logloss:0.085715\n",
            "[347]\ttrain-logloss:0.005232\teval-logloss:0.085793\n",
            "[348]\ttrain-logloss:0.005227\teval-logloss:0.085835\n",
            "[349]\ttrain-logloss:0.005221\teval-logloss:0.085734\n",
            "[350]\ttrain-logloss:0.005216\teval-logloss:0.085658\n",
            "[351]\ttrain-logloss:0.00521\teval-logloss:0.08573\n",
            "[352]\ttrain-logloss:0.005205\teval-logloss:0.085807\n",
            "[353]\ttrain-logloss:0.0052\teval-logloss:0.085706\n",
            "[354]\ttrain-logloss:0.005195\teval-logloss:0.085659\n",
            "[355]\ttrain-logloss:0.005189\teval-logloss:0.085701\n",
            "[356]\ttrain-logloss:0.005184\teval-logloss:0.085628\n",
            "[357]\ttrain-logloss:0.005179\teval-logloss:0.085529\n",
            "[358]\ttrain-logloss:0.005174\teval-logloss:0.085604\n",
            "[359]\ttrain-logloss:0.005169\teval-logloss:0.085676\n",
            "[360]\ttrain-logloss:0.005164\teval-logloss:0.085579\n",
            "[361]\ttrain-logloss:0.005159\teval-logloss:0.085601\n",
            "[362]\ttrain-logloss:0.005153\teval-logloss:0.085643\n",
            "[363]\ttrain-logloss:0.005149\teval-logloss:0.085713\n",
            "[364]\ttrain-logloss:0.005144\teval-logloss:0.085787\n",
            "[365]\ttrain-logloss:0.005139\teval-logloss:0.085689\n",
            "[366]\ttrain-logloss:0.005134\teval-logloss:0.08573\n",
            "[367]\ttrain-logloss:0.005129\teval-logloss:0.085684\n",
            "[368]\ttrain-logloss:0.005124\teval-logloss:0.085589\n",
            "[369]\ttrain-logloss:0.005119\teval-logloss:0.085516\n",
            "[370]\ttrain-logloss:0.005114\teval-logloss:0.085588\n",
            "[371]\ttrain-logloss:0.00511\teval-logloss:0.085495\n",
            "[372]\ttrain-logloss:0.005105\teval-logloss:0.085564\n",
            "[373]\ttrain-logloss:0.0051\teval-logloss:0.085605\n",
            "[374]\ttrain-logloss:0.005096\teval-logloss:0.085626\n",
            "[375]\ttrain-logloss:0.005091\teval-logloss:0.085535\n",
            "[376]\ttrain-logloss:0.005086\teval-logloss:0.085606\n",
            "[377]\ttrain-logloss:0.005082\teval-logloss:0.085674\n",
            "[378]\ttrain-logloss:0.005077\teval-logloss:0.085714\n",
            "[379]\ttrain-logloss:0.005073\teval-logloss:0.085624\n",
            "[380]\ttrain-logloss:0.005068\teval-logloss:0.085579\n",
            "[381]\ttrain-logloss:0.005064\teval-logloss:0.085618\n",
            "[382]\ttrain-logloss:0.00506\teval-logloss:0.085639\n",
            "[383]\ttrain-logloss:0.005055\teval-logloss:0.08555\n",
            "[384]\ttrain-logloss:0.005051\teval-logloss:0.085617\n",
            "[385]\ttrain-logloss:0.005047\teval-logloss:0.085621\n",
            "[386]\ttrain-logloss:0.005042\teval-logloss:0.085551\n",
            "[387]\ttrain-logloss:0.005038\teval-logloss:0.085463\n",
            "[388]\ttrain-logloss:0.005034\teval-logloss:0.085502\n",
            "[389]\ttrain-logloss:0.005029\teval-logloss:0.085459\n",
            "[390]\ttrain-logloss:0.005025\teval-logloss:0.085321\n",
            "[391]\ttrain-logloss:0.005021\teval-logloss:0.085389\n",
            "[392]\ttrain-logloss:0.005017\teval-logloss:0.085303\n",
            "[393]\ttrain-logloss:0.005013\teval-logloss:0.085369\n",
            "[394]\ttrain-logloss:0.005009\teval-logloss:0.085301\n",
            "[395]\ttrain-logloss:0.005005\teval-logloss:0.085368\n",
            "[396]\ttrain-logloss:0.005\teval-logloss:0.085283\n",
            "[397]\ttrain-logloss:0.004996\teval-logloss:0.08532\n",
            "[398]\ttrain-logloss:0.004992\teval-logloss:0.085279\n",
            "[399]\ttrain-logloss:0.004988\teval-logloss:0.085196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1dqwaopj2ph",
        "outputId": "21874dd5-8b3b-4583-9eb0-ca5d2c1a8285"
      },
      "source": [
        "pred_probs = xgb_model.predict(dtest)\n",
        "print('predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
        "print(np.round(pred_probs[:10],3))\n",
        "\n",
        "# 예측 확률이 0.5 보다 크면 1 , 그렇지 않으면 0 으로 예측값 결정하여 List 객체인 preds에 저장 \n",
        "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
        "print('예측값 10개만 표시:',preds[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict( ) 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
            "[0.95  0.003 0.9   0.086 0.993 1.    1.    0.999 0.998 0.   ]\n",
            "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-OHCeTrj5pl"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "# 수정된 get_clf_eval() 함수 \n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "    confusion = confusion_matrix( y_test, pred) # confusion[i][j]:i가 j로 예측된 수\n",
        "    accuracy = accuracy_score(y_test , pred)\n",
        "    precision = precision_score(y_test , pred)\n",
        "    recall = recall_score(y_test , pred)\n",
        "    f1 = f1_score(y_test,pred)\n",
        "    # ROC-AUC 추가 \n",
        "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "    print('오차 행렬')\n",
        "    print(confusion)\n",
        "    # ROC-AUC print 추가\n",
        "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
        "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jgRWnMqj7Qg",
        "outputId": "2c02ac16-6745-4a6b-b1b1-b9c799e2d032"
      },
      "source": [
        "get_clf_eval(y_test , preds, pred_probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "오차 행렬\n",
            "[[35  2]\n",
            " [ 1 76]]\n",
            "정확도: 0.9737, 정밀도: 0.9744, 재현율: 0.9870,    F1: 0.9806, AUC:0.9951\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}